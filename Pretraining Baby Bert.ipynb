{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14650219,"sourceType":"datasetVersion","datasetId":9358820}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"5932e8ad-ebcb-4ce1-ae7c-a3b60d21d7b0","cell_type":"markdown","source":"### Importing The Required Libraries","metadata":{}},{"id":"26ee5db8-79c6-4f67-87de-ab789cf7e24d","cell_type":"code","source":"!pip install torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 \\\n  --index-url https://download.pytorch.org/whl/cu121\n!pip install torchtext==0.18.0 --no-deps\n  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:37:34.800886Z","iopub.execute_input":"2026-01-29T08:37:34.801606Z","iopub.status.idle":"2026-01-29T08:40:29.715753Z","shell.execute_reply.started":"2026-01-29T08:37:34.801577Z","shell.execute_reply":"2026-01-29T08:40:29.714711Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu121\nCollecting torch==2.3.0+cu121\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (780.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.18.0+cu121\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchaudio==2.3.0+cu121\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (4.15.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (2.0.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (11.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0+cu121) (12.6.85)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0+cu121) (3.0.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0+cu121) (1.3.0)\nInstalling collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.6.77\n    Uninstalling nvidia-nvtx-cu12-12.6.77:\n      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.27.3\n    Uninstalling nvidia-nccl-cu12-2.27.3:\n      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n  Attempting uninstall: torch\n    Found existing installation: torch 2.8.0+cu126\n    Uninstalling torch-2.8.0+cu126:\n      Successfully uninstalled torch-2.8.0+cu126\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.23.0+cu126\n    Uninstalling torchvision-0.23.0+cu126:\n      Successfully uninstalled torchvision-0.23.0+cu126\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.8.0+cu126\n    Uninstalling torchaudio-2.8.0+cu126:\n      Successfully uninstalled torchaudio-2.8.0+cu126\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0+cu121 torchaudio-2.3.0+cu121 torchvision-0.18.0+cu121\nCollecting torchtext==0.18.0\n  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\nDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torchtext\nSuccessfully installed torchtext-0.18.0\n","output_type":"stream"}],"execution_count":1},{"id":"64bec614-65d1-4b2a-866b-5dd518d9ecd7","cell_type":"code","source":"import torchtext\ntorchtext.disable_torchtext_deprecation_warning()\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch import Tensor\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torch.nn import Transformer\nfrom transformers import BertTokenizer\nfrom torch.optim import Adam\nfrom torch.nn import CrossEntropyLoss\nfrom torchtext.vocab import Vocab,build_vocab_from_iterator\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.datasets import IMDB\nimport random\nfrom itertools import chain\nimport pandas as pd\nfrom copy import deepcopy\nimport csv\nimport json\nimport math\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom transformers import get_linear_schedule_with_warmup\n\n# You can also use this section to suppress warnings generated by your code:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport torch.optim as optim\nimport time ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:40:29.717699Z","iopub.execute_input":"2026-01-29T08:40:29.718064Z","iopub.status.idle":"2026-01-29T08:40:37.375135Z","shell.execute_reply.started":"2026-01-29T08:40:29.718033Z","shell.execute_reply":"2026-01-29T08:40:37.374465Z"}},"outputs":[],"execution_count":2},{"id":"7f82a84a-d9b0-4b91-99d9-5301b8801cd9","cell_type":"markdown","source":"### Loading The CSV Dataset","metadata":{}},{"id":"8970c2af-a70b-4f66-90c8-0c696dd8eb8b","cell_type":"code","source":"class BERTCSVDataset(Dataset):\n    def __init__(self,filename):\n        self.data=pd.read_csv(filename)\n        self.tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self,idx):\n        row = self.data.iloc[idx]\n        try:\n            \n            bert_input = torch.tensor(json.loads(row['BERT Input']), dtype=torch.long)\n            bert_label = torch.tensor(json.loads(row['BERT Label']), dtype=torch.long)\n            segment_label = torch.tensor([int(x) for x in row['Segment Label'].split(',')], dtype=torch.long)\n            is_next = torch.tensor(row['Is Next'], dtype=torch.long)\n            original_text = row['Original Text']  # If you want to use it\n        except json.JSONDecodeError as e:\n            print(f\"Error decoding JSON for row {idx}: {e}\")\n            print(\"BERT Input:\", row['BERT Input'])\n            print(\"BERT Label:\", row['BERT Label'])\n            return None  \n\n            # Tokenizing the original text with BERT\n        encoded_input = self.tokenizer.encode_plus(\n            original_text,\n            add_special_tokens=True,\n            padding='max_length',\n            truncation=True,\n            max_length=512,\n            return_tensors=\"pt\"\n        )\n\n        input_ids = encoded_input['input_ids'].squeeze()\n        attention_mask = encoded_input['attention_mask'].squeeze()\n\n        return(bert_input, bert_label, segment_label, is_next, input_ids, attention_mask, original_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:40:37.376079Z","iopub.execute_input":"2026-01-29T08:40:37.376469Z","iopub.status.idle":"2026-01-29T08:40:37.384682Z","shell.execute_reply.started":"2026-01-29T08:40:37.376426Z","shell.execute_reply":"2026-01-29T08:40:37.383687Z"}},"outputs":[],"execution_count":3},{"id":"b81aac33-e55c-4b4c-9b2d-ac5aa6b6ef82","cell_type":"code","source":"PAD_IDX = 0\ndef collate_batch(batch):\n    bert_inputs_batch, bert_labels_batch, segment_labels_batch, is_nexts_batch,input_ids_batch,attention_mask_batch,original_text_battch = [], [], [], [],[],[],[]\n    for bert_input, bert_label, segment_label, is_next,input_ids,attention_mask,original_text in batch:\n        bert_inputs_batch.append(torch.tensor(bert_input[:512], dtype=torch.long))\n        bert_labels_batch.append(torch.tensor(bert_label[:512], dtype=torch.long))\n        segment_labels_batch.append(torch.tensor(segment_label[:512], dtype=torch.long))\n        is_nexts_batch.append(is_next)\n        input_ids_batch.append(input_ids)\n        attention_mask_batch.append(attention_mask)\n        original_text_battch.append(original_text)\n    bert_inputs_final = pad_sequence(bert_inputs_batch, padding_value=PAD_IDX, batch_first=True)\n    bert_labels_final = pad_sequence(bert_labels_batch, padding_value=PAD_IDX, batch_first=True)\n    segment_labels_final = pad_sequence(segment_labels_batch, padding_value=PAD_IDX, batch_first=True)\n    is_nexts_batch = torch.tensor(is_nexts_batch, dtype=torch.long)\n    return bert_inputs_final, bert_labels_final, segment_labels_final, is_nexts_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:40:37.385852Z","iopub.execute_input":"2026-01-29T08:40:37.386193Z","iopub.status.idle":"2026-01-29T08:40:37.408975Z","shell.execute_reply.started":"2026-01-29T08:40:37.386162Z","shell.execute_reply":"2026-01-29T08:40:37.408306Z"}},"outputs":[],"execution_count":4},{"id":"851da32f-5962-42f9-ad14-6b72c00e1f12","cell_type":"code","source":"BATCH_SIZE = 6\n\ntrain_dataset_path = '/kaggle/input/bert-dataset/bert_dataset/bert_train_data.csv'\ntest_dataset_path = '/kaggle/input/bert-dataset/bert_dataset/bert_test_data.csv'\n\ntrain_dataset = BERTCSVDataset(train_dataset_path)\ntest_dataset = BERTCSVDataset(test_dataset_path)\ntrain_dataloader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_batch)\ntest_dataloader=DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T14:37:10.234429Z","iopub.execute_input":"2026-01-29T14:37:10.234769Z","iopub.status.idle":"2026-01-29T14:37:17.991359Z","shell.execute_reply.started":"2026-01-29T14:37:10.234741Z","shell.execute_reply":"2026-01-29T14:37:17.990541Z"}},"outputs":[],"execution_count":33},{"id":"9d62c296-7b39-496c-ad54-ee6dea9e9de2","cell_type":"markdown","source":"### Model Creation","metadata":{}},{"id":"c090a0b7-eba5-4970-8a6f-62f44e6feba9","cell_type":"code","source":"EMBEDDING_DIM=10\nclass TokenEmbedding(nn.Module):\n    def __init__(self,vocab_size,embed_dim):\n        super(TokenEmbedding,self).__init__()\n        self.embedding=nn.Embedding(vocab_size,embed_dim)\n        self.embed_dim=embed_dim\n    def forward(self, tokens: Tensor):\n        return self.embedding(tokens.long()) * math.sqrt(self.embed_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:00.832011Z","iopub.execute_input":"2026-01-29T08:41:00.832338Z","iopub.status.idle":"2026-01-29T08:41:00.837385Z","shell.execute_reply.started":"2026-01-29T08:41:00.832306Z","shell.execute_reply":"2026-01-29T08:41:00.836579Z"}},"outputs":[],"execution_count":6},{"id":"789251a6-fd72-4573-8cc3-551ebbb69c2e","cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, emb_size: int, dropout: float, maxlen: int = 512):\n        super().__init__()\n\n        position = torch.arange(0, maxlen).unsqueeze(1)\n        div_term = torch.exp(\n            torch.arange(0, emb_size, 2) * (-math.log(10000.0) / emb_size)\n        )\n\n        pe = torch.zeros(maxlen, emb_size)\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n\n        self.register_buffer(\"pos_embedding\", pe)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, token_embedding: torch.Tensor):\n        \"\"\"\n        token_embedding: [batch_size, seq_len, emb_size]\n        \"\"\"\n        seq_len = token_embedding.size(1)\n        token_embedding = token_embedding + self.pos_embedding[:, :seq_len, :]\n        return self.dropout(token_embedding)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:00.838528Z","iopub.execute_input":"2026-01-29T08:41:00.838928Z","iopub.status.idle":"2026-01-29T08:41:00.974377Z","shell.execute_reply.started":"2026-01-29T08:41:00.838905Z","shell.execute_reply":"2026-01-29T08:41:00.973755Z"}},"outputs":[],"execution_count":7},{"id":"3c4d3daf-8b26-4829-a884-7103ffbb93a9","cell_type":"code","source":"class BERTEmbedding(nn.Module):\n    def __init__(self, vocab_size, embed_dim, dropout=0.1):\n        super().__init__()\n\n        self.token_embedding = TokenEmbedding(vocab_size, embed_dim)\n        self.positional_encoding = PositionalEncoding(embed_dim, dropout)\n        self.segment_embedding = nn.Embedding(3, embed_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, bert_inputs, segment_labels):\n        \"\"\"\n        bert_inputs:   [batch_size, seq_len]\n        segment_labels:[batch_size, seq_len]\n        \"\"\"\n\n        token_embeddings = self.token_embedding(bert_inputs)\n        position_embeddings = self.positional_encoding(token_embeddings)\n        segment_embeddings = self.segment_embedding(segment_labels)\n\n        x = token_embeddings + position_embeddings + segment_embeddings\n        x = self.dropout(x)\n\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:00.975321Z","iopub.execute_input":"2026-01-29T08:41:00.975645Z","iopub.status.idle":"2026-01-29T08:41:00.991419Z","shell.execute_reply.started":"2026-01-29T08:41:00.975617Z","shell.execute_reply":"2026-01-29T08:41:00.990725Z"}},"outputs":[],"execution_count":8},{"id":"469e5541-b7d4-4e09-a2ec-eb104658cfca","cell_type":"code","source":"VOCAB_SIZE=147161\nbatch=2\ncount=0\nfor batch in train_dataloader:\n    bert_input,bert_label,segement_label,is_next=[b for b in batch]\n    \n    count+=1\n    if count==5:\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:00.992461Z","iopub.execute_input":"2026-01-29T08:41:00.992716Z","iopub.status.idle":"2026-01-29T08:41:01.094220Z","shell.execute_reply.started":"2026-01-29T08:41:00.992695Z","shell.execute_reply":"2026-01-29T08:41:01.093375Z"}},"outputs":[],"execution_count":9},{"id":"f5c1f8c8-22e1-4f9f-80a1-bf588832ac10","cell_type":"code","source":"bert_input.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.095106Z","iopub.execute_input":"2026-01-29T08:41:01.095401Z","iopub.status.idle":"2026-01-29T08:41:01.100270Z","shell.execute_reply.started":"2026-01-29T08:41:01.095378Z","shell.execute_reply":"2026-01-29T08:41:01.099556Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 78])"},"metadata":{}}],"execution_count":10},{"id":"94f112d8-4af2-44ce-b0ba-e49cd65ae509","cell_type":"code","source":"segement_label.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.101140Z","iopub.execute_input":"2026-01-29T08:41:01.101440Z","iopub.status.idle":"2026-01-29T08:41:01.114562Z","shell.execute_reply.started":"2026-01-29T08:41:01.101411Z","shell.execute_reply":"2026-01-29T08:41:01.114051Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 78])"},"metadata":{}}],"execution_count":11},{"id":"e1a7a36e-6ef0-48b8-a216-e4bce654cd79","cell_type":"code","source":"bert_label.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.115406Z","iopub.execute_input":"2026-01-29T08:41:01.115748Z","iopub.status.idle":"2026-01-29T08:41:01.129499Z","shell.execute_reply.started":"2026-01-29T08:41:01.115711Z","shell.execute_reply":"2026-01-29T08:41:01.128959Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 78])"},"metadata":{}}],"execution_count":12},{"id":"7ea50992-af8b-43cb-85ff-2222936d77cc","cell_type":"code","source":"is_next.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.130196Z","iopub.execute_input":"2026-01-29T08:41:01.130416Z","iopub.status.idle":"2026-01-29T08:41:01.144225Z","shell.execute_reply.started":"2026-01-29T08:41:01.130397Z","shell.execute_reply":"2026-01-29T08:41:01.143490Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"torch.Size([2])"},"metadata":{}}],"execution_count":13},{"id":"253e7636-7186-44df-b074-41605ce1937f","cell_type":"code","source":"is_next","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.147223Z","iopub.execute_input":"2026-01-29T08:41:01.147528Z","iopub.status.idle":"2026-01-29T08:41:01.159962Z","shell.execute_reply.started":"2026-01-29T08:41:01.147496Z","shell.execute_reply":"2026-01-29T08:41:01.159339Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"tensor([0, 1])"},"metadata":{}}],"execution_count":14},{"id":"4805fd3b-d46c-4fd3-b27b-a4b709473915","cell_type":"code","source":"bert_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.160880Z","iopub.execute_input":"2026-01-29T08:41:01.161183Z","iopub.status.idle":"2026-01-29T08:41:01.175353Z","shell.execute_reply.started":"2026-01-29T08:41:01.161152Z","shell.execute_reply":"2026-01-29T08:41:01.174838Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"tensor([[    1,    21,    13,     7,     3,    12,     3,    52,   619,   322,\n          1926,    48,     3,     6,     2,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,    38,   464,   438,     3,\n             3, 36586,   158,    35,     3,   151,   198,     5,  3487,    27,\n             7,    38,   338,     7,    38,  2278,     3,     8,    38,  9685,\n             6,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0],\n        [    1,    31,     3,   939,   519,    17,   123,   435,   406,   188,\n           775, 10428,     3,    25,     3,     3,   125,  2193,    13,  1739,\n            11,   118,   238, 20191,     7,    35,     3,   901,  1328,   195,\n             9,  4368,   217,     6,     2,     0,     0,     0,     0,     3,\n          2938,   545,   197,     5,  2585,  1286,     3,     5,   101,   185,\n             3,     5,    24,     7,    25,   161,    42,     3,    36,     5,\n             3,    10,    44,  2247,     7,    76,  1545,   257,   177,    48,\n          1733,  6714,    31,     9,    92,   266,     6,     2]])"},"metadata":{}}],"execution_count":15},{"id":"e6213f95-2ca2-4c73-92ab-7bc36c4dd8e6","cell_type":"code","source":"segement_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.176137Z","iopub.execute_input":"2026-01-29T08:41:01.176529Z","iopub.status.idle":"2026-01-29T08:41:01.194511Z","shell.execute_reply.started":"2026-01-29T08:41:01.176505Z","shell.execute_reply":"2026-01-29T08:41:01.193825Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n         2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n         2, 2, 2, 2, 2, 2]])"},"metadata":{}}],"execution_count":16},{"id":"5d8327ce-8484-44e7-8351-152832915839","cell_type":"code","source":"# Instantiate the TokenEmbedding \ntoken_embedding = TokenEmbedding(VOCAB_SIZE, embed_dim=EMBEDDING_DIM )\n\n# Get the token embeddings for a sample input\nt_embeddings = token_embedding(bert_input)\n#Each token is transformed into a tensor of size emb_size\nprint(f\"Dimensions of token embeddings: {t_embeddings.size()}\") # Expected: (sequence_length, batch_size, EMBEDDING_DIM)\n#Check the embedded vectors for first 3 tokens of the first sample in the batch\n# you get embeddings[i,0,:] where i refers to the i'th token of the first sample in the batch (b=0)\nfor i in range(2):\n    print(f\"Token Embeddings for the {i}th token of the first sample: {t_embeddings[i,0,:]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.195410Z","iopub.execute_input":"2026-01-29T08:41:01.195675Z","iopub.status.idle":"2026-01-29T08:41:01.226819Z","shell.execute_reply.started":"2026-01-29T08:41:01.195655Z","shell.execute_reply":"2026-01-29T08:41:01.226022Z"}},"outputs":[{"name":"stdout","text":"Dimensions of token embeddings: torch.Size([2, 78, 10])\nToken Embeddings for the 0th token of the first sample: tensor([-1.9143,  0.6985,  4.7210, -1.6886, -2.6555,  1.8882, -1.5148,  4.5452,\n         0.8053,  3.1830], grad_fn=<SliceBackward0>)\nToken Embeddings for the 1th token of the first sample: tensor([-1.9143,  0.6985,  4.7210, -1.6886, -2.6555,  1.8882, -1.5148,  4.5452,\n         0.8053,  3.1830], grad_fn=<SliceBackward0>)\n","output_type":"stream"}],"execution_count":17},{"id":"3caadec7-ef16-424a-ad27-f1b9b6750c5c","cell_type":"markdown","source":"### Bert Model Architecture","metadata":{}},{"id":"516282b7-eeda-4993-a0d5-6a9bc81dc243","cell_type":"code","source":"class BERT(nn.Module):\n    def __init__(self,vocab_size,embed_dim,num_layers,n_head,dropout):\n        super().__init__()\n        self.d_model = d_model\n        self.n_layers = n_layers\n        self.heads = heads\n        self.embedding=BERTEmbedding(vocab_size,embed_dim)\n        encoder_layer=nn.TransformerEncoderLayer(d_model=embed_dim,nhead=n_head,dropout=dropout,batch_first=True)\n        self.encoder=nn.TransformerEncoder(encoder_layer,num_layers=num_layers)\n        self.NextSentencePrediction=nn.Linear(embed_dim,2)\n        self.MaskedPrediction=nn.Linear(embed_dim,vocab_size)\n    def forward(self,bert_input,segement_label):\n        padding_mask=(bert_input==PAD_IDX)\n        x=self.embedding(bert_input,segement_label)\n        values_after_encoding=self.encoder(x,src_key_padding_mask=padding_mask)\n        next_sentence=self.NextSentencePrediction(values_after_encoding[:,0,:])\n        masked_language=self.MaskedPrediction(values_after_encoding)\n        return next_sentence,masked_language ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.227780Z","iopub.execute_input":"2026-01-29T08:41:01.228048Z","iopub.status.idle":"2026-01-29T08:41:01.235162Z","shell.execute_reply.started":"2026-01-29T08:41:01.228028Z","shell.execute_reply":"2026-01-29T08:41:01.234393Z"}},"outputs":[],"execution_count":18},{"id":"f10ab092-7b9e-4088-9a5a-08f9ee1a9825","cell_type":"code","source":"EMBEDDING_DIM = 10\nvocab_size = 147161\nd_model = EMBEDDING_DIM  \nn_layers = 2\ninitial_heads = 12\ninitial_heads = 2\nheads = initial_heads - d_model % initial_heads\ndropout = 0.1  \nmodel = BERT(vocab_size, d_model, n_layers, heads, dropout)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.236008Z","iopub.execute_input":"2026-01-29T08:41:01.236236Z","iopub.status.idle":"2026-01-29T08:41:01.288512Z","shell.execute_reply.started":"2026-01-29T08:41:01.236198Z","shell.execute_reply":"2026-01-29T08:41:01.287758Z"}},"outputs":[],"execution_count":19},{"id":"adad3fb5-d612-47a6-a7a6-37909d920d84","cell_type":"code","source":"if torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = nn.DataParallel(model)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.289472Z","iopub.execute_input":"2026-01-29T08:41:01.289754Z","iopub.status.idle":"2026-01-29T08:41:01.531435Z","shell.execute_reply.started":"2026-01-29T08:41:01.289722Z","shell.execute_reply":"2026-01-29T08:41:01.530733Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs!\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): BERT(\n    (embedding): BERTEmbedding(\n      (token_embedding): TokenEmbedding(\n        (embedding): Embedding(147161, 10)\n      )\n      (positional_encoding): PositionalEncoding(\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (segment_embedding): Embedding(3, 10)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): TransformerEncoder(\n      (layers): ModuleList(\n        (0-1): 2 x TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=10, out_features=10, bias=True)\n          )\n          (linear1): Linear(in_features=10, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=10, bias=True)\n          (norm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (NextSentencePrediction): Linear(in_features=10, out_features=2, bias=True)\n    (MaskedPrediction): Linear(in_features=10, out_features=147161, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":20},{"id":"4770eb38-66f7-4cb3-9cf6-6cc8d3498aa5","cell_type":"markdown","source":"### Evaluation","metadata":{}},{"id":"e6c4f75b-d5a5-48b4-9140-94bb73eb4642","cell_type":"code","source":"PAD_IDX=0\nloss_ns=nn.CrossEntropyLoss()\nloss_mlm=nn.CrossEntropyLoss(ignore_index=PAD_IDX)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.532295Z","iopub.execute_input":"2026-01-29T08:41:01.532566Z","iopub.status.idle":"2026-01-29T08:41:01.536642Z","shell.execute_reply.started":"2026-01-29T08:41:01.532535Z","shell.execute_reply":"2026-01-29T08:41:01.535824Z"}},"outputs":[],"execution_count":21},{"id":"3e893f19-51e8-4e94-98c9-1ce88d3d2644","cell_type":"code","source":"def evaluate(dataloader, model, loss_ns, loss_mlm):\n    model.eval()\n    total_loss = 0\n    \n    for batch in dataloader:\n        bert_input, bert_label, segment_label, is_next = [b.to(device) for b in batch]\n        \n        next_sentence_prediction, masked_language = model(bert_input, segment_label)\n        \n        l_ns = loss_ns(next_sentence_prediction, is_next.view(-1))\n        l_mlm = loss_mlm(masked_language.reshape(-1, masked_language.size(-1)), bert_label.reshape(-1))\n        \n        loss = l_ns + l_mlm\n        total_loss += loss.item()\n        \n    return total_loss / len(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:01.537544Z","iopub.execute_input":"2026-01-29T08:41:01.537814Z","iopub.status.idle":"2026-01-29T08:41:01.554079Z","shell.execute_reply.started":"2026-01-29T08:41:01.537760Z","shell.execute_reply":"2026-01-29T08:41:01.553505Z"}},"outputs":[],"execution_count":22},{"id":"85ec20a3-280e-4410-9212-2db740953889","cell_type":"markdown","source":"### Training","metadata":{}},{"id":"28f953b5-0593-4116-90e4-398501ccce6b","cell_type":"code","source":"BATCH_SIZE = 6\n\ntrain_dataset_path = '/kaggle/input/bert-dataset/bert_dataset/bert_train_data_sampled.csv'\ntest_dataset_path = '/kaggle/input/bert-dataset/bert_dataset/bert_test_data_sampled.csv'\n\ntrain_dataset = BERTCSVDataset(train_dataset_path)\ntest_dataset = BERTCSVDataset(test_dataset_path)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T14:46:30.859287Z","iopub.execute_input":"2026-01-29T14:46:30.860053Z","iopub.status.idle":"2026-01-29T14:46:31.817571Z","shell.execute_reply.started":"2026-01-29T14:46:30.860019Z","shell.execute_reply":"2026-01-29T14:46:31.817009Z"}},"outputs":[],"execution_count":35},{"id":"2ed90608-d11b-4abd-8942-350d4f87614b","cell_type":"code","source":"loss=evaluate(train_dataloader,model,loss_ns,loss_mlm)\nloss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T08:41:03.994969Z","iopub.execute_input":"2026-01-29T08:41:03.995293Z","iopub.status.idle":"2026-01-29T08:43:01.999396Z","shell.execute_reply.started":"2026-01-29T08:41:03.995264Z","shell.execute_reply":"2026-01-29T08:43:01.998724Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"12.768256727218628"},"metadata":{}}],"execution_count":24},{"id":"5bf8362c-0d5e-42d5-8c82-bcef59189854","cell_type":"code","source":"import time\nfrom tqdm import tqdm\nfrom torch.optim import Adam\nfrom transformers import get_linear_schedule_with_warmup\n\nfrom torch.optim import Adam\nfrom transformers import get_linear_schedule_with_warmup\nfrom tqdm import tqdm\nnum_epochs=100\noptimizer = Adam(model.parameters(), lr=5e-5, weight_decay=0.01)\ntotal_steps = num_epochs * len(train_dataloader)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * 0.1), num_training_steps=total_steps)\ncheck_loss=10\nfor epoch in range(num_epochs):\n    model.train()\n    start_time=time.time()\n    total_loss = 0.0\n    \n\n    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\")\n    \n    for batch in progress_bar:\n\n        bert_inputs, bert_labels, segment_labels, is_nexts = [b.to(device) for b in batch]\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        next_pred, mask_pred = model(bert_inputs, segment_labels)\n        \n        # Calculate individual losses\n        loss_n = loss_ns(next_pred, is_nexts)\n        loss_m = loss_mlm(mask_pred.view(-1, mask_pred.size(-1)), bert_labels.view(-1))\n        \n        # Combine losses\n        loss = loss_n + loss_m\n        \n        if torch.isnan(loss):\n            print(\"Warning: NaN loss detected!\")\n            continue\n        \n        # Backward pass\n        loss.backward()\n        \n        # Stability: Clip gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        \n        optimizer.step()\n        scheduler.step()\n        \n        total_loss += loss.item()\n        \n        # Optional: Update progress bar with current loss\n        progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n    end_time=time.time()\n    avg_epoch_loss = total_loss / len(train_dataloader)\n    print(\"Time Taken for the epoch\",(int)(end_time-start_time))\n    print(f\"Epoch {epoch+1} Complete - Average Loss: {avg_epoch_loss:.4f}\")\n    if(avg_epoch_loss<check_loss):\n        torch.save(model.state_dict(), \"bert.pt\")\n        print(\"Model saved at epoch\",epoch)\n        check_loss=avg_epoch_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T09:30:53.173568Z","iopub.execute_input":"2026-01-29T09:30:53.174144Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 1667/1667 [03:02<00:00,  9.12it/s, loss=11.7924]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 182\nEpoch 1 Complete - Average Loss: 11.5558\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 1667/1667 [03:00<00:00,  9.25it/s, loss=11.3332]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 180\nEpoch 2 Complete - Average Loss: 11.5257\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 1667/1667 [02:59<00:00,  9.31it/s, loss=10.8581]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 179\nEpoch 3 Complete - Average Loss: 11.4632\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 1667/1667 [02:57<00:00,  9.37it/s, loss=10.9780]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 4 Complete - Average Loss: 11.3654\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 1667/1667 [02:58<00:00,  9.35it/s, loss=11.0431]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 178\nEpoch 5 Complete - Average Loss: 11.2293\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 1667/1667 [02:58<00:00,  9.32it/s, loss=10.6366]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 178\nEpoch 6 Complete - Average Loss: 11.0543\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 1667/1667 [02:59<00:00,  9.31it/s, loss=10.7951]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 179\nEpoch 7 Complete - Average Loss: 10.8592\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 1667/1667 [02:57<00:00,  9.39it/s, loss=10.3345]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 8 Complete - Average Loss: 10.6602\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 1667/1667 [02:58<00:00,  9.32it/s, loss=10.1665]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 178\nEpoch 9 Complete - Average Loss: 10.4816\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 1667/1667 [02:57<00:00,  9.37it/s, loss=10.6151]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 10 Complete - Average Loss: 10.3355\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 1667/1667 [02:57<00:00,  9.37it/s, loss=10.6051]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 11 Complete - Average Loss: 10.2212\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 1667/1667 [02:57<00:00,  9.37it/s, loss=9.8430] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 12 Complete - Average Loss: 10.1400\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 1667/1667 [02:57<00:00,  9.39it/s, loss=9.4483] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 13 Complete - Average Loss: 10.0697\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 1667/1667 [02:57<00:00,  9.42it/s, loss=9.7246] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 14 Complete - Average Loss: 10.0171\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 1667/1667 [02:57<00:00,  9.38it/s, loss=10.5532]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 15 Complete - Average Loss: 9.9757\nModel saved at epoch 14\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|██████████| 1667/1667 [02:57<00:00,  9.39it/s, loss=10.1220]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 16 Complete - Average Loss: 9.9491\nModel saved at epoch 15\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 1667/1667 [02:57<00:00,  9.38it/s, loss=9.2464] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 17 Complete - Average Loss: 9.9180\nModel saved at epoch 16\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|██████████| 1667/1667 [02:56<00:00,  9.43it/s, loss=11.0779]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 18 Complete - Average Loss: 9.8861\nModel saved at epoch 17\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19: 100%|██████████| 1667/1667 [02:57<00:00,  9.42it/s, loss=10.0991]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 19 Complete - Average Loss: 9.8728\nModel saved at epoch 18\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20: 100%|██████████| 1667/1667 [02:58<00:00,  9.35it/s, loss=9.3954] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 178\nEpoch 20 Complete - Average Loss: 9.8502\nModel saved at epoch 19\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|██████████| 1667/1667 [02:57<00:00,  9.41it/s, loss=8.5922] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 21 Complete - Average Loss: 9.8347\nModel saved at epoch 20\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22: 100%|██████████| 1667/1667 [02:58<00:00,  9.35it/s, loss=9.9479] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 178\nEpoch 22 Complete - Average Loss: 9.8259\nModel saved at epoch 21\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23: 100%|██████████| 1667/1667 [02:56<00:00,  9.43it/s, loss=9.2367] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 23 Complete - Average Loss: 9.8131\nModel saved at epoch 22\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24: 100%|██████████| 1667/1667 [02:57<00:00,  9.40it/s, loss=9.3633] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 24 Complete - Average Loss: 9.8031\nModel saved at epoch 23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25: 100%|██████████| 1667/1667 [02:56<00:00,  9.42it/s, loss=9.6524] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 25 Complete - Average Loss: 9.7973\nModel saved at epoch 24\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|██████████| 1667/1667 [02:56<00:00,  9.44it/s, loss=8.4176] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 26 Complete - Average Loss: 9.7837\nModel saved at epoch 25\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27: 100%|██████████| 1667/1667 [02:56<00:00,  9.45it/s, loss=10.5796]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 27 Complete - Average Loss: 9.7846\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28: 100%|██████████| 1667/1667 [02:56<00:00,  9.43it/s, loss=10.2866]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 28 Complete - Average Loss: 9.7677\nModel saved at epoch 27\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29: 100%|██████████| 1667/1667 [02:58<00:00,  9.32it/s, loss=9.6662] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 178\nEpoch 29 Complete - Average Loss: 9.7697\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30: 100%|██████████| 1667/1667 [02:57<00:00,  9.37it/s, loss=9.0754] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 30 Complete - Average Loss: 9.7642\nModel saved at epoch 29\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|██████████| 1667/1667 [02:59<00:00,  9.31it/s, loss=10.9829]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 179\nEpoch 31 Complete - Average Loss: 9.7578\nModel saved at epoch 30\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32: 100%|██████████| 1667/1667 [02:57<00:00,  9.40it/s, loss=9.8492] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 32 Complete - Average Loss: 9.7617\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33: 100%|██████████| 1667/1667 [02:55<00:00,  9.49it/s, loss=10.1768]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 175\nEpoch 33 Complete - Average Loss: 9.7513\nModel saved at epoch 32\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34: 100%|██████████| 1667/1667 [02:57<00:00,  9.37it/s, loss=8.9346] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 34 Complete - Average Loss: 9.7440\nModel saved at epoch 33\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35: 100%|██████████| 1667/1667 [02:57<00:00,  9.38it/s, loss=10.8880]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 35 Complete - Average Loss: 9.7451\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36: 100%|██████████| 1667/1667 [02:56<00:00,  9.42it/s, loss=9.8405] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 36 Complete - Average Loss: 9.7438\nModel saved at epoch 35\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37: 100%|██████████| 1667/1667 [02:57<00:00,  9.41it/s, loss=9.4687] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 37 Complete - Average Loss: 9.7400\nModel saved at epoch 36\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38: 100%|██████████| 1667/1667 [02:57<00:00,  9.40it/s, loss=9.4942] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 38 Complete - Average Loss: 9.7384\nModel saved at epoch 37\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39: 100%|██████████| 1667/1667 [02:56<00:00,  9.45it/s, loss=10.4423]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 39 Complete - Average Loss: 9.7343\nModel saved at epoch 38\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40: 100%|██████████| 1667/1667 [02:55<00:00,  9.51it/s, loss=10.3031]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 175\nEpoch 40 Complete - Average Loss: 9.7329\nModel saved at epoch 39\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41: 100%|██████████| 1667/1667 [02:55<00:00,  9.49it/s, loss=9.1215] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 175\nEpoch 41 Complete - Average Loss: 9.7254\nModel saved at epoch 40\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42: 100%|██████████| 1667/1667 [02:55<00:00,  9.51it/s, loss=9.4364] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 175\nEpoch 42 Complete - Average Loss: 9.7261\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43: 100%|██████████| 1667/1667 [02:55<00:00,  9.52it/s, loss=10.0196]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 175\nEpoch 43 Complete - Average Loss: 9.7300\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44: 100%|██████████| 1667/1667 [02:55<00:00,  9.48it/s, loss=10.2131]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 175\nEpoch 44 Complete - Average Loss: 9.7223\nModel saved at epoch 43\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45: 100%|██████████| 1667/1667 [02:55<00:00,  9.50it/s, loss=10.2663]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 175\nEpoch 45 Complete - Average Loss: 9.7235\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46: 100%|██████████| 1667/1667 [02:55<00:00,  9.48it/s, loss=10.8488]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 175\nEpoch 46 Complete - Average Loss: 9.7245\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47: 100%|██████████| 1667/1667 [02:56<00:00,  9.47it/s, loss=10.7290]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 47 Complete - Average Loss: 9.7241\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48: 100%|██████████| 1667/1667 [02:55<00:00,  9.49it/s, loss=10.6480]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 175\nEpoch 48 Complete - Average Loss: 9.7153\nModel saved at epoch 47\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49: 100%|██████████| 1667/1667 [02:56<00:00,  9.47it/s, loss=9.6051] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 49 Complete - Average Loss: 9.7155\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50: 100%|██████████| 1667/1667 [02:56<00:00,  9.46it/s, loss=10.3551]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 50 Complete - Average Loss: 9.7136\nModel saved at epoch 49\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51: 100%|██████████| 1667/1667 [02:57<00:00,  9.39it/s, loss=9.8205] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 51 Complete - Average Loss: 9.7068\nModel saved at epoch 50\n","output_type":"stream"},{"name":"stderr","text":"Epoch 52: 100%|██████████| 1667/1667 [02:59<00:00,  9.31it/s, loss=10.5395]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 179\nEpoch 52 Complete - Average Loss: 9.7148\n","output_type":"stream"},{"name":"stderr","text":"Epoch 53: 100%|██████████| 1667/1667 [02:59<00:00,  9.30it/s, loss=11.0825]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 179\nEpoch 53 Complete - Average Loss: 9.7079\n","output_type":"stream"},{"name":"stderr","text":"Epoch 54: 100%|██████████| 1667/1667 [02:56<00:00,  9.42it/s, loss=9.3020] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 54 Complete - Average Loss: 9.7007\nModel saved at epoch 53\n","output_type":"stream"},{"name":"stderr","text":"Epoch 55: 100%|██████████| 1667/1667 [02:56<00:00,  9.44it/s, loss=9.5079] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 55 Complete - Average Loss: 9.7016\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56: 100%|██████████| 1667/1667 [02:56<00:00,  9.42it/s, loss=8.7766] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 56 Complete - Average Loss: 9.7002\nModel saved at epoch 55\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57: 100%|██████████| 1667/1667 [02:56<00:00,  9.46it/s, loss=10.2187]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 57 Complete - Average Loss: 9.6991\nModel saved at epoch 56\n","output_type":"stream"},{"name":"stderr","text":"Epoch 58: 100%|██████████| 1667/1667 [02:56<00:00,  9.42it/s, loss=9.3279] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 58 Complete - Average Loss: 9.7001\n","output_type":"stream"},{"name":"stderr","text":"Epoch 59: 100%|██████████| 1667/1667 [02:56<00:00,  9.42it/s, loss=10.5127]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 59 Complete - Average Loss: 9.6940\nModel saved at epoch 58\n","output_type":"stream"},{"name":"stderr","text":"Epoch 60: 100%|██████████| 1667/1667 [02:56<00:00,  9.42it/s, loss=9.9732] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 60 Complete - Average Loss: 9.6933\nModel saved at epoch 59\n","output_type":"stream"},{"name":"stderr","text":"Epoch 61: 100%|██████████| 1667/1667 [02:56<00:00,  9.47it/s, loss=9.5161] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 61 Complete - Average Loss: 9.6915\nModel saved at epoch 60\n","output_type":"stream"},{"name":"stderr","text":"Epoch 62: 100%|██████████| 1667/1667 [02:56<00:00,  9.43it/s, loss=9.1433] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 62 Complete - Average Loss: 9.6911\nModel saved at epoch 61\n","output_type":"stream"},{"name":"stderr","text":"Epoch 63: 100%|██████████| 1667/1667 [02:57<00:00,  9.42it/s, loss=8.8610] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 63 Complete - Average Loss: 9.6903\nModel saved at epoch 62\n","output_type":"stream"},{"name":"stderr","text":"Epoch 64: 100%|██████████| 1667/1667 [02:56<00:00,  9.44it/s, loss=10.8476]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 64 Complete - Average Loss: 9.6884\nModel saved at epoch 63\n","output_type":"stream"},{"name":"stderr","text":"Epoch 65: 100%|██████████| 1667/1667 [02:57<00:00,  9.40it/s, loss=9.0008] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 65 Complete - Average Loss: 9.6871\nModel saved at epoch 64\n","output_type":"stream"},{"name":"stderr","text":"Epoch 66: 100%|██████████| 1667/1667 [02:57<00:00,  9.42it/s, loss=9.5333] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 66 Complete - Average Loss: 9.6808\nModel saved at epoch 65\n","output_type":"stream"},{"name":"stderr","text":"Epoch 67: 100%|██████████| 1667/1667 [02:56<00:00,  9.43it/s, loss=10.3694]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 67 Complete - Average Loss: 9.6840\n","output_type":"stream"},{"name":"stderr","text":"Epoch 68: 100%|██████████| 1667/1667 [02:57<00:00,  9.38it/s, loss=10.0634]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 68 Complete - Average Loss: 9.6845\n","output_type":"stream"},{"name":"stderr","text":"Epoch 69: 100%|██████████| 1667/1667 [02:58<00:00,  9.34it/s, loss=9.7839] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 178\nEpoch 69 Complete - Average Loss: 9.6824\n","output_type":"stream"},{"name":"stderr","text":"Epoch 70: 100%|██████████| 1667/1667 [03:00<00:00,  9.23it/s, loss=10.6859]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 180\nEpoch 70 Complete - Average Loss: 9.6768\nModel saved at epoch 69\n","output_type":"stream"},{"name":"stderr","text":"Epoch 71: 100%|██████████| 1667/1667 [02:58<00:00,  9.31it/s, loss=9.9756] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 178\nEpoch 71 Complete - Average Loss: 9.6801\n","output_type":"stream"},{"name":"stderr","text":"Epoch 72: 100%|██████████| 1667/1667 [02:57<00:00,  9.37it/s, loss=10.8645]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 72 Complete - Average Loss: 9.6745\nModel saved at epoch 71\n","output_type":"stream"},{"name":"stderr","text":"Epoch 73: 100%|██████████| 1667/1667 [02:58<00:00,  9.36it/s, loss=8.7249] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 178\nEpoch 73 Complete - Average Loss: 9.6744\nModel saved at epoch 72\n","output_type":"stream"},{"name":"stderr","text":"Epoch 74: 100%|██████████| 1667/1667 [02:57<00:00,  9.40it/s, loss=9.6614] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 74 Complete - Average Loss: 9.6742\nModel saved at epoch 73\n","output_type":"stream"},{"name":"stderr","text":"Epoch 75: 100%|██████████| 1667/1667 [02:57<00:00,  9.39it/s, loss=9.3674] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 75 Complete - Average Loss: 9.6779\n","output_type":"stream"},{"name":"stderr","text":"Epoch 76: 100%|██████████| 1667/1667 [02:56<00:00,  9.42it/s, loss=9.7142] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 76 Complete - Average Loss: 9.6725\nModel saved at epoch 75\n","output_type":"stream"},{"name":"stderr","text":"Epoch 77: 100%|██████████| 1667/1667 [02:58<00:00,  9.33it/s, loss=9.4806] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 178\nEpoch 77 Complete - Average Loss: 9.6681\nModel saved at epoch 76\n","output_type":"stream"},{"name":"stderr","text":"Epoch 78: 100%|██████████| 1667/1667 [02:58<00:00,  9.35it/s, loss=9.0464] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 178\nEpoch 78 Complete - Average Loss: 9.6730\n","output_type":"stream"},{"name":"stderr","text":"Epoch 79: 100%|██████████| 1667/1667 [02:57<00:00,  9.38it/s, loss=8.7664] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 79 Complete - Average Loss: 9.6711\n","output_type":"stream"},{"name":"stderr","text":"Epoch 80: 100%|██████████| 1667/1667 [02:57<00:00,  9.38it/s, loss=9.2978] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 80 Complete - Average Loss: 9.6668\nModel saved at epoch 79\n","output_type":"stream"},{"name":"stderr","text":"Epoch 81: 100%|██████████| 1667/1667 [02:56<00:00,  9.42it/s, loss=9.3726] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 81 Complete - Average Loss: 9.6729\n","output_type":"stream"},{"name":"stderr","text":"Epoch 82: 100%|██████████| 1667/1667 [02:59<00:00,  9.30it/s, loss=10.4611]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 179\nEpoch 82 Complete - Average Loss: 9.6707\n","output_type":"stream"},{"name":"stderr","text":"Epoch 83: 100%|██████████| 1667/1667 [03:00<00:00,  9.25it/s, loss=10.3548]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 180\nEpoch 83 Complete - Average Loss: 9.6690\n","output_type":"stream"},{"name":"stderr","text":"Epoch 84: 100%|██████████| 1667/1667 [02:56<00:00,  9.43it/s, loss=10.6710]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 84 Complete - Average Loss: 9.6653\nModel saved at epoch 83\n","output_type":"stream"},{"name":"stderr","text":"Epoch 85: 100%|██████████| 1667/1667 [02:57<00:00,  9.40it/s, loss=10.5335]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 85 Complete - Average Loss: 9.6657\n","output_type":"stream"},{"name":"stderr","text":"Epoch 86: 100%|██████████| 1667/1667 [02:56<00:00,  9.42it/s, loss=9.9060] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 176\nEpoch 86 Complete - Average Loss: 9.6665\n","output_type":"stream"},{"name":"stderr","text":"Epoch 89: 100%|██████████| 1667/1667 [02:57<00:00,  9.38it/s, loss=10.7882]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 89 Complete - Average Loss: 9.6671\n","output_type":"stream"},{"name":"stderr","text":"Epoch 95: 100%|██████████| 1667/1667 [02:57<00:00,  9.39it/s, loss=9.2717] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 177\nEpoch 95 Complete - Average Loss: 9.6650\n","output_type":"stream"},{"name":"stderr","text":"Epoch 99:  96%|█████████▌| 1602/1667 [02:52<00:08,  7.84it/s, loss=9.7880] ","output_type":"stream"}],"execution_count":null},{"id":"8354e720-b10b-487a-81e5-aa96ddf57e1a","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}