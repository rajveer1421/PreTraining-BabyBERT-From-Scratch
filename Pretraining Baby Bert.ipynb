{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14650219,"sourceType":"datasetVersion","datasetId":9358820}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"5932e8ad-ebcb-4ce1-ae7c-a3b60d21d7b0","cell_type":"markdown","source":"### Importing The Required Libraries","metadata":{}},{"id":"26ee5db8-79c6-4f67-87de-ab789cf7e24d","cell_type":"code","source":"!pip install torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 \\\n  --index-url https://download.pytorch.org/whl/cu121\n!pip install torchtext==0.18.0 --no-deps\n  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:06:28.670553Z","iopub.execute_input":"2026-01-28T17:06:28.671178Z","iopub.status.idle":"2026-01-28T17:08:53.158889Z","shell.execute_reply.started":"2026-01-28T17:06:28.671150Z","shell.execute_reply":"2026-01-28T17:08:53.158126Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu121\nCollecting torch==2.3.0+cu121\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (780.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.18.0+cu121\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hCollecting torchaudio==2.3.0+cu121\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (4.15.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (2.0.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (11.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0+cu121) (12.6.85)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0+cu121) (3.0.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0+cu121) (1.3.0)\nInstalling collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.6.77\n    Uninstalling nvidia-nvtx-cu12-12.6.77:\n      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.27.3\n    Uninstalling nvidia-nccl-cu12-2.27.3:\n      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n  Attempting uninstall: torch\n    Found existing installation: torch 2.8.0+cu126\n    Uninstalling torch-2.8.0+cu126:\n      Successfully uninstalled torch-2.8.0+cu126\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.23.0+cu126\n    Uninstalling torchvision-0.23.0+cu126:\n      Successfully uninstalled torchvision-0.23.0+cu126\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.8.0+cu126\n    Uninstalling torchaudio-2.8.0+cu126:\n      Successfully uninstalled torchaudio-2.8.0+cu126\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0+cu121 torchaudio-2.3.0+cu121 torchvision-0.18.0+cu121\nCollecting torchtext==0.18.0\n  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\nDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: torchtext\nSuccessfully installed torchtext-0.18.0\n","output_type":"stream"}],"execution_count":1},{"id":"64bec614-65d1-4b2a-866b-5dd518d9ecd7","cell_type":"code","source":"import torchtext\ntorchtext.disable_torchtext_deprecation_warning()\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch import Tensor\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torch.nn import Transformer\nfrom transformers import BertTokenizer\nfrom torch.optim import Adam\nfrom torch.nn import CrossEntropyLoss\nfrom torchtext.vocab import Vocab,build_vocab_from_iterator\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.datasets import IMDB\nimport random\nfrom itertools import chain\nimport pandas as pd\nfrom copy import deepcopy\nimport csv\nimport json\nimport math\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom transformers import get_linear_schedule_with_warmup\n\n# You can also use this section to suppress warnings generated by your code:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport torch.optim as optim\nimport time ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:08:53.160758Z","iopub.execute_input":"2026-01-28T17:08:53.160982Z","iopub.status.idle":"2026-01-28T17:08:57.363628Z","shell.execute_reply.started":"2026-01-28T17:08:53.160955Z","shell.execute_reply":"2026-01-28T17:08:57.363027Z"}},"outputs":[],"execution_count":2},{"id":"7f82a84a-d9b0-4b91-99d9-5301b8801cd9","cell_type":"markdown","source":"### Loading The CSV Dataset","metadata":{}},{"id":"8970c2af-a70b-4f66-90c8-0c696dd8eb8b","cell_type":"code","source":"class BERTCSVDataset(Dataset):\n    def __init__(self,filename):\n        self.data=pd.read_csv(filename)\n        self.tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self,idx):\n        row = self.data.iloc[idx]\n        try:\n            \n            bert_input = torch.tensor(json.loads(row['BERT Input']), dtype=torch.long)\n            bert_label = torch.tensor(json.loads(row['BERT Label']), dtype=torch.long)\n            segment_label = torch.tensor([int(x) for x in row['Segment Label'].split(',')], dtype=torch.long)\n            is_next = torch.tensor(row['Is Next'], dtype=torch.long)\n            original_text = row['Original Text']  # If you want to use it\n        except json.JSONDecodeError as e:\n            print(f\"Error decoding JSON for row {idx}: {e}\")\n            print(\"BERT Input:\", row['BERT Input'])\n            print(\"BERT Label:\", row['BERT Label'])\n            return None  \n\n            # Tokenizing the original text with BERT\n        encoded_input = self.tokenizer.encode_plus(\n            original_text,\n            add_special_tokens=True,\n            padding='max_length',\n            truncation=True,\n            max_length=512,\n            return_tensors=\"pt\"\n        )\n\n        input_ids = encoded_input['input_ids'].squeeze()\n        attention_mask = encoded_input['attention_mask'].squeeze()\n\n        return(bert_input, bert_label, segment_label, is_next, input_ids, attention_mask, original_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:15:03.507800Z","iopub.execute_input":"2026-01-28T17:15:03.508563Z","iopub.status.idle":"2026-01-28T17:15:03.516023Z","shell.execute_reply.started":"2026-01-28T17:15:03.508531Z","shell.execute_reply":"2026-01-28T17:15:03.515143Z"}},"outputs":[],"execution_count":27},{"id":"b81aac33-e55c-4b4c-9b2d-ac5aa6b6ef82","cell_type":"code","source":"PAD_IDX = 0\ndef collate_batch(batch):\n    bert_inputs_batch, bert_labels_batch, segment_labels_batch, is_nexts_batch,input_ids_batch,attention_mask_batch,original_text_battch = [], [], [], [],[],[],[]\n    for bert_input, bert_label, segment_label, is_next,input_ids,attention_mask,original_text in batch:\n        bert_inputs_batch.append(torch.tensor(bert_input[:512], dtype=torch.long))\n        bert_labels_batch.append(torch.tensor(bert_label[:512], dtype=torch.long))\n        segment_labels_batch.append(torch.tensor(segment_label[:512], dtype=torch.long))\n        is_nexts_batch.append(is_next)\n        input_ids_batch.append(input_ids)\n        attention_mask_batch.append(attention_mask)\n        original_text_battch.append(original_text)\n    bert_inputs_final = pad_sequence(bert_inputs_batch, padding_value=PAD_IDX, batch_first=True)\n    bert_labels_final = pad_sequence(bert_labels_batch, padding_value=PAD_IDX, batch_first=True)\n    segment_labels_final = pad_sequence(segment_labels_batch, padding_value=PAD_IDX, batch_first=True)\n    is_nexts_batch = torch.tensor(is_nexts_batch, dtype=torch.long)\n    return bert_inputs_final, bert_labels_final, segment_labels_final, is_nexts_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:04:51.326550Z","iopub.execute_input":"2026-01-28T18:04:51.327093Z","iopub.status.idle":"2026-01-28T18:04:51.333211Z","shell.execute_reply.started":"2026-01-28T18:04:51.327064Z","shell.execute_reply":"2026-01-28T18:04:51.332543Z"}},"outputs":[],"execution_count":51},{"id":"851da32f-5962-42f9-ad14-6b72c00e1f12","cell_type":"code","source":"BATCH_SIZE = 2\n\ntrain_dataset_path = '/kaggle/input/bert-dataset/bert_dataset/bert_train_data.csv'\ntest_dataset_path = '/kaggle/input/bert-dataset/bert_dataset/bert_test_data.csv'\n\ntrain_dataset = BERTCSVDataset(train_dataset_path)\ntest_dataset = BERTCSVDataset(test_dataset_path)\ntrain_dataloader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_batch)\ntest_dataloader=DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:04:52.487578Z","iopub.execute_input":"2026-01-28T18:04:52.488208Z","iopub.status.idle":"2026-01-28T18:05:00.609364Z","shell.execute_reply.started":"2026-01-28T18:04:52.488177Z","shell.execute_reply":"2026-01-28T18:05:00.608459Z"}},"outputs":[],"execution_count":52},{"id":"9d62c296-7b39-496c-ad54-ee6dea9e9de2","cell_type":"markdown","source":"### Model Creation","metadata":{}},{"id":"c090a0b7-eba5-4970-8a6f-62f44e6feba9","cell_type":"code","source":"EMBEDDING_DIM=10\nclass TokenEmbedding(nn.Module):\n    def __init__(self,vocab_size,embed_dim):\n        super(TokenEmbedding,self).__init__()\n        self.embedding=nn.Embedding(vocab_size,embed_dim)\n        self.embed_dim=embed_dim\n    def forward(self, tokens: Tensor):\n        return self.embedding(tokens.long()) * math.sqrt(self.embed_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:00.610890Z","iopub.execute_input":"2026-01-28T18:05:00.611830Z","iopub.status.idle":"2026-01-28T18:05:00.616653Z","shell.execute_reply.started":"2026-01-28T18:05:00.611804Z","shell.execute_reply":"2026-01-28T18:05:00.615779Z"}},"outputs":[],"execution_count":53},{"id":"789251a6-fd72-4573-8cc3-551ebbb69c2e","cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, emb_size: int, dropout: float, maxlen: int = 512):\n        super().__init__()\n\n        position = torch.arange(0, maxlen).unsqueeze(1)\n        div_term = torch.exp(\n            torch.arange(0, emb_size, 2) * (-math.log(10000.0) / emb_size)\n        )\n\n        pe = torch.zeros(maxlen, emb_size)\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n\n        self.register_buffer(\"pos_embedding\", pe)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, token_embedding: torch.Tensor):\n        \"\"\"\n        token_embedding: [batch_size, seq_len, emb_size]\n        \"\"\"\n        seq_len = token_embedding.size(1)\n        token_embedding = token_embedding + self.pos_embedding[:, :seq_len, :]\n        return self.dropout(token_embedding)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:00.617454Z","iopub.execute_input":"2026-01-28T18:05:00.618625Z","iopub.status.idle":"2026-01-28T18:05:00.633509Z","shell.execute_reply.started":"2026-01-28T18:05:00.618571Z","shell.execute_reply":"2026-01-28T18:05:00.632792Z"}},"outputs":[],"execution_count":54},{"id":"3c4d3daf-8b26-4829-a884-7103ffbb93a9","cell_type":"code","source":"class BERTEmbedding(nn.Module):\n    def __init__(self, vocab_size, embed_dim, dropout=0.1):\n        super().__init__()\n\n        self.token_embedding = TokenEmbedding(vocab_size, embed_dim)\n        self.positional_encoding = PositionalEncoding(embed_dim, dropout)\n        self.segment_embedding = nn.Embedding(3, embed_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, bert_inputs, segment_labels):\n        \"\"\"\n        bert_inputs:   [batch_size, seq_len]\n        segment_labels:[batch_size, seq_len]\n        \"\"\"\n\n        token_embeddings = self.token_embedding(bert_inputs)\n        position_embeddings = self.positional_encoding(token_embeddings)\n        segment_embeddings = self.segment_embedding(segment_labels)\n\n        x = token_embeddings + position_embeddings + segment_embeddings\n        x = self.dropout(x)\n\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:00.635106Z","iopub.execute_input":"2026-01-28T18:05:00.635547Z","iopub.status.idle":"2026-01-28T18:05:00.645412Z","shell.execute_reply.started":"2026-01-28T18:05:00.635526Z","shell.execute_reply":"2026-01-28T18:05:00.644603Z"}},"outputs":[],"execution_count":55},{"id":"469e5541-b7d4-4e09-a2ec-eb104658cfca","cell_type":"code","source":"VOCAB_SIZE=147161\nbatch=2\ncount=0\nfor batch in train_dataloader:\n    bert_input,bert_label,segement_label,is_next=[b for b in batch]\n    \n    count+=1\n    if count==5:\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:00.646342Z","iopub.execute_input":"2026-01-28T18:05:00.646921Z","iopub.status.idle":"2026-01-28T18:05:00.717391Z","shell.execute_reply.started":"2026-01-28T18:05:00.646901Z","shell.execute_reply":"2026-01-28T18:05:00.716865Z"}},"outputs":[],"execution_count":56},{"id":"f5c1f8c8-22e1-4f9f-80a1-bf588832ac10","cell_type":"code","source":"bert_input.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:01.114013Z","iopub.execute_input":"2026-01-28T18:05:01.114583Z","iopub.status.idle":"2026-01-28T18:05:01.118810Z","shell.execute_reply.started":"2026-01-28T18:05:01.114559Z","shell.execute_reply":"2026-01-28T18:05:01.118207Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 82])"},"metadata":{}}],"execution_count":57},{"id":"94f112d8-4af2-44ce-b0ba-e49cd65ae509","cell_type":"code","source":"segement_label.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:01.611648Z","iopub.execute_input":"2026-01-28T18:05:01.612142Z","iopub.status.idle":"2026-01-28T18:05:01.616818Z","shell.execute_reply.started":"2026-01-28T18:05:01.612120Z","shell.execute_reply":"2026-01-28T18:05:01.616018Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 82])"},"metadata":{}}],"execution_count":58},{"id":"e1a7a36e-6ef0-48b8-a216-e4bce654cd79","cell_type":"code","source":"bert_label.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:02.159451Z","iopub.execute_input":"2026-01-28T18:05:02.160014Z","iopub.status.idle":"2026-01-28T18:05:02.164135Z","shell.execute_reply.started":"2026-01-28T18:05:02.159991Z","shell.execute_reply":"2026-01-28T18:05:02.163638Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 82])"},"metadata":{}}],"execution_count":59},{"id":"7ea50992-af8b-43cb-85ff-2222936d77cc","cell_type":"code","source":"is_next.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:03.465053Z","iopub.execute_input":"2026-01-28T18:05:03.465662Z","iopub.status.idle":"2026-01-28T18:05:03.470343Z","shell.execute_reply.started":"2026-01-28T18:05:03.465636Z","shell.execute_reply":"2026-01-28T18:05:03.469550Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"torch.Size([2])"},"metadata":{}}],"execution_count":60},{"id":"253e7636-7186-44df-b074-41605ce1937f","cell_type":"code","source":"is_next","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:03.834829Z","iopub.execute_input":"2026-01-28T18:05:03.835147Z","iopub.status.idle":"2026-01-28T18:05:03.840533Z","shell.execute_reply.started":"2026-01-28T18:05:03.835126Z","shell.execute_reply":"2026-01-28T18:05:03.839710Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"tensor([1, 1])"},"metadata":{}}],"execution_count":61},{"id":"4805fd3b-d46c-4fd3-b27b-a4b709473915","cell_type":"code","source":"bert_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:04.116011Z","iopub.execute_input":"2026-01-28T18:05:04.116599Z","iopub.status.idle":"2026-01-28T18:05:04.121945Z","shell.execute_reply.started":"2026-01-28T18:05:04.116579Z","shell.execute_reply":"2026-01-28T18:05:04.121207Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"tensor([[    1,     3,    20,   538,    44,   580,    11,  9535,   142,     3,\n             5,  1005,    10,  7645,     3,     8,    49,    36,     3,   264,\n           292,    18,    36,  4079,    15,   399, 39504,     3,   210,   112,\n             7,    25,    17,     3,    70,   122,    36,   940,     6,     2,\n             0,  1043,     3,    22,    47,   119,   164,   264,    70,    32,\n            66,     3,     5,     3,     3,    63,    42, 12506,     5,    24,\n             7,    14,    13, 17904,    18,     3,   212,    42,   107,     3,\n             9,   131,    31,   264,    23,     3,  2052,   699,  1352,   197,\n             6,     2],\n        [    1,  2580,    12,    19,   617,    21,     3, 30250,    10,  1770,\n            22,     3,   440,     6,     2,    28,   632,   603,   164,     3,\n            32,     3,     3,    10,    44,  1222,   242,     6,     2,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0]])"},"metadata":{}}],"execution_count":62},{"id":"e6213f95-2ca2-4c73-92ab-7bc36c4dd8e6","cell_type":"code","source":"segement_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:05.423686Z","iopub.execute_input":"2026-01-28T18:05:05.424286Z","iopub.status.idle":"2026-01-28T18:05:05.429748Z","shell.execute_reply.started":"2026-01-28T18:05:05.424260Z","shell.execute_reply":"2026-01-28T18:05:05.429132Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2,\n         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n         2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n         2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"},"metadata":{}}],"execution_count":63},{"id":"5d8327ce-8484-44e7-8351-152832915839","cell_type":"code","source":"# Instantiate the TokenEmbedding \ntoken_embedding = TokenEmbedding(VOCAB_SIZE, embed_dim=EMBEDDING_DIM )\n\n# Get the token embeddings for a sample input\nt_embeddings = token_embedding(bert_input)\n#Each token is transformed into a tensor of size emb_size\nprint(f\"Dimensions of token embeddings: {t_embeddings.size()}\") # Expected: (sequence_length, batch_size, EMBEDDING_DIM)\n#Check the embedded vectors for first 3 tokens of the first sample in the batch\n# you get embeddings[i,0,:] where i refers to the i'th token of the first sample in the batch (b=0)\nfor i in range(2):\n    print(f\"Token Embeddings for the {i}th token of the first sample: {t_embeddings[i,0,:]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:05.729450Z","iopub.execute_input":"2026-01-28T18:05:05.730032Z","iopub.status.idle":"2026-01-28T18:05:05.749080Z","shell.execute_reply.started":"2026-01-28T18:05:05.730010Z","shell.execute_reply":"2026-01-28T18:05:05.748292Z"}},"outputs":[{"name":"stdout","text":"Dimensions of token embeddings: torch.Size([2, 82, 10])\nToken Embeddings for the 0th token of the first sample: tensor([-3.3162, -2.3625, -4.0100, -1.6696,  2.6844, -2.4756, -1.2127, -0.9825,\n         0.1128,  0.8203], grad_fn=<SliceBackward0>)\nToken Embeddings for the 1th token of the first sample: tensor([-3.3162, -2.3625, -4.0100, -1.6696,  2.6844, -2.4756, -1.2127, -0.9825,\n         0.1128,  0.8203], grad_fn=<SliceBackward0>)\n","output_type":"stream"}],"execution_count":64},{"id":"3caadec7-ef16-424a-ad27-f1b9b6750c5c","cell_type":"markdown","source":"### Bert Model Architecture","metadata":{}},{"id":"516282b7-eeda-4993-a0d5-6a9bc81dc243","cell_type":"code","source":"class BERT(nn.Module):\n    def __init__(self,vocab_size,embed_dim,num_layers,n_head,dropout):\n        super().__init__()\n        self.d_model = d_model\n        self.n_layers = n_layers\n        self.heads = heads\n        self.embedding=BERTEmbedding(vocab_size,embed_dim)\n        encoder_layer=nn.TransformerEncoderLayer(d_model=embed_dim,nhead=n_head,dropout=dropout,batch_first=True)\n        self.encoder=nn.TransformerEncoder(encoder_layer,num_layers=num_layers)\n        self.NextSentencePrediction=nn.Linear(embed_dim,2)\n        self.MaskedPrediction=nn.Linear(embed_dim,vocab_size)\n    def forward(self,bert_input,segement_label):\n        padding_mask=(bert_input==PAD_IDX)\n        x=self.embedding(bert_input,segement_label)\n        values_after_encoding=self.encoder(x,src_key_padding_mask=padding_mask)\n        next_sentence=self.NextSentencePrediction(values_after_encoding[:,0,:])\n        masked_language=self.MaskedPrediction(values_after_encoding)\n        return next_sentence,masked_language ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:08.115019Z","iopub.execute_input":"2026-01-28T18:05:08.115430Z","iopub.status.idle":"2026-01-28T18:05:08.121580Z","shell.execute_reply.started":"2026-01-28T18:05:08.115402Z","shell.execute_reply":"2026-01-28T18:05:08.120733Z"}},"outputs":[],"execution_count":65},{"id":"f10ab092-7b9e-4088-9a5a-08f9ee1a9825","cell_type":"code","source":"EMBEDDING_DIM = 10\nvocab_size = 147161\nd_model = EMBEDDING_DIM  \nn_layers = 2\ninitial_heads = 12\ninitial_heads = 2\nheads = initial_heads - d_model % initial_heads\ndropout = 0.1  \nmodel = BERT(vocab_size, d_model, n_layers, heads, dropout)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:09.721586Z","iopub.execute_input":"2026-01-28T18:05:09.722247Z","iopub.status.idle":"2026-01-28T18:05:09.760246Z","shell.execute_reply.started":"2026-01-28T18:05:09.722221Z","shell.execute_reply":"2026-01-28T18:05:09.759503Z"}},"outputs":[],"execution_count":66},{"id":"adad3fb5-d612-47a6-a7a6-37909d920d84","cell_type":"code","source":"if torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = nn.DataParallel(model)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:12.315785Z","iopub.execute_input":"2026-01-28T18:05:12.316730Z","iopub.status.idle":"2026-01-28T18:05:12.328110Z","shell.execute_reply.started":"2026-01-28T18:05:12.316689Z","shell.execute_reply":"2026-01-28T18:05:12.327263Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs!\n","output_type":"stream"},{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): BERT(\n    (embedding): BERTEmbedding(\n      (token_embedding): TokenEmbedding(\n        (embedding): Embedding(147161, 10)\n      )\n      (positional_encoding): PositionalEncoding(\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (segment_embedding): Embedding(3, 10)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): TransformerEncoder(\n      (layers): ModuleList(\n        (0-1): 2 x TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=10, out_features=10, bias=True)\n          )\n          (linear1): Linear(in_features=10, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=10, bias=True)\n          (norm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (NextSentencePrediction): Linear(in_features=10, out_features=2, bias=True)\n    (MaskedPrediction): Linear(in_features=10, out_features=147161, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":67},{"id":"4770eb38-66f7-4cb3-9cf6-6cc8d3498aa5","cell_type":"markdown","source":"### Evaluation","metadata":{}},{"id":"e6c4f75b-d5a5-48b4-9140-94bb73eb4642","cell_type":"code","source":"PAD_IDX=0\nloss_ns=nn.CrossEntropyLoss()\nloss_mlm=nn.CrossEntropyLoss(ignore_index=PAD_IDX)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:15.520040Z","iopub.execute_input":"2026-01-28T18:05:15.520567Z","iopub.status.idle":"2026-01-28T18:05:15.524719Z","shell.execute_reply.started":"2026-01-28T18:05:15.520523Z","shell.execute_reply":"2026-01-28T18:05:15.524021Z"}},"outputs":[],"execution_count":68},{"id":"3e893f19-51e8-4e94-98c9-1ce88d3d2644","cell_type":"code","source":"def evaluate(dataloader, model, loss_ns, loss_mlm):\n    model.eval()\n    total_loss = 0\n    \n    for batch in dataloader:\n        bert_input, bert_label, segment_label, is_next = [b.to(device) for b in batch]\n        \n        next_sentence_prediction, masked_language = model(bert_input, segment_label)\n        \n        l_ns = loss_ns(next_sentence_prediction, is_next.view(-1))\n        l_mlm = loss_mlm(masked_language.reshape(-1, masked_language.size(-1)), bert_label.reshape(-1))\n        \n        loss = l_ns + l_mlm\n        total_loss += loss.item()\n        \n    return total_loss / len(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:05:19.358290Z","iopub.execute_input":"2026-01-28T18:05:19.359094Z","iopub.status.idle":"2026-01-28T18:05:19.364415Z","shell.execute_reply.started":"2026-01-28T18:05:19.359065Z","shell.execute_reply":"2026-01-28T18:05:19.363541Z"}},"outputs":[],"execution_count":69},{"id":"85ec20a3-280e-4410-9212-2db740953889","cell_type":"markdown","source":"### Training","metadata":{}},{"id":"28f953b5-0593-4116-90e4-398501ccce6b","cell_type":"code","source":"BATCH_SIZE = 2\n\ntrain_dataset_path = '/kaggle/input/bert-dataset/bert_dataset/bert_train_data_sampled.csv'\ntest_dataset_path = '/kaggle/input/bert-dataset/bert_dataset/bert_test_data_sampled.csv'\n\ntrain_dataset = BERTCSVDataset(train_dataset_path)\ntest_dataset = BERTCSVDataset(test_dataset_path)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:30:41.829156Z","iopub.execute_input":"2026-01-28T18:30:41.829648Z","iopub.status.idle":"2026-01-28T18:30:43.894099Z","shell.execute_reply.started":"2026-01-28T18:30:41.829620Z","shell.execute_reply":"2026-01-28T18:30:43.893500Z"}},"outputs":[],"execution_count":72},{"id":"2ed90608-d11b-4abd-8942-350d4f87614b","cell_type":"code","source":"loss=evaluate(train_dataloader,model,loss_ns,loss_mlm)\nloss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:30:47.285022Z","iopub.execute_input":"2026-01-28T18:30:47.285519Z","iopub.status.idle":"2026-01-28T18:32:53.115808Z","shell.execute_reply.started":"2026-01-28T18:30:47.285492Z","shell.execute_reply":"2026-01-28T18:32:53.115266Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"13.080436336517334"},"metadata":{}}],"execution_count":73},{"id":"5bf8362c-0d5e-42d5-8c82-bcef59189854","cell_type":"code","source":"import time\nfrom tqdm import tqdm\nfrom torch.optim import Adam\nfrom transformers import get_linear_schedule_with_warmup\n\nfrom torch.optim import Adam\nfrom transformers import get_linear_schedule_with_warmup\nfrom tqdm import tqdm\nnum_epochs=25\noptimizer = Adam(model.parameters(), lr=1e-4, weight_decay=0.01)\ntotal_steps = num_epochs * len(train_dataloader)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * 0.1), num_training_steps=total_steps)\ncheck_loss=10\nfor epoch in range(num_epochs):\n    model.train()\n    start_time=time.time()\n    total_loss = 0.0\n    \n\n    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\")\n    \n    for batch in progress_bar:\n\n        bert_inputs, bert_labels, segment_labels, is_nexts = [b.to(device) for b in batch]\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        next_pred, mask_pred = model(bert_inputs, segment_labels)\n        \n        # Calculate individual losses\n        loss_n = loss_ns(next_pred, is_nexts)\n        loss_m = loss_mlm(mask_pred.view(-1, mask_pred.size(-1)), bert_labels.view(-1))\n        \n        # Combine losses\n        loss = loss_n + loss_m\n        \n        if torch.isnan(loss):\n            print(\"Warning: NaN loss detected!\")\n            continue\n        \n        # Backward pass\n        loss.backward()\n        \n        # Stability: Clip gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        \n        optimizer.step()\n        scheduler.step()\n        \n        total_loss += loss.item()\n        \n        # Optional: Update progress bar with current loss\n        progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n    end_time=time.time()\n    avg_epoch_loss = total_loss / len(train_dataloader)\n    print(\"Time Taken for the epoch\",(int)(end_time-start_time))\n    print(f\"Epoch {epoch+1} Complete - Average Loss: {avg_epoch_loss:.4f}\")\n    if(avg_epoch_loss<check_loss):\n        torch.save(model.state_dict(), \"bert.pt\")\n        print(\"Model saved at epoch\",epoch)\n        check_loss=avg_epoch_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:32:53.117165Z","iopub.execute_input":"2026-01-28T18:32:53.117493Z","iopub.status.idle":"2026-01-28T19:42:02.311060Z","shell.execute_reply.started":"2026-01-28T18:32:53.117470Z","shell.execute_reply":"2026-01-28T19:42:02.310125Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 5000/5000 [03:10<00:00, 26.20it/s, loss=12.3792]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 1 Complete - Average Loss: 12.6317\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  25%|██▌       | 1261/5000 [00:47<02:20, 26.52it/s, loss=12.5705]","output_type":"stream"},{"name":"stdout","text":"Warning: NaN loss detected!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 5000/5000 [03:10<00:00, 26.19it/s, loss=12.0744]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 2 Complete - Average Loss: 12.1916\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 5000/5000 [03:11<00:00, 26.13it/s, loss=11.8983]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 191\nEpoch 3 Complete - Average Loss: 11.3157\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 5000/5000 [03:11<00:00, 26.17it/s, loss=9.6708] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 191\nEpoch 4 Complete - Average Loss: 10.4902\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:  70%|██████▉   | 3492/5000 [02:13<00:58, 25.56it/s, loss=9.8337] ","output_type":"stream"},{"name":"stdout","text":"Warning: NaN loss detected!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 5000/5000 [03:11<00:00, 26.16it/s, loss=9.2737] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 191\nEpoch 5 Complete - Average Loss: 10.2227\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 5000/5000 [03:10<00:00, 26.20it/s, loss=9.6485] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 6 Complete - Average Loss: 10.1184\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 5000/5000 [03:10<00:00, 26.18it/s, loss=10.8710]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 7 Complete - Average Loss: 10.0550\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 5000/5000 [03:10<00:00, 26.24it/s, loss=10.0097]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 8 Complete - Average Loss: 10.0247\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:  38%|███▊      | 1879/5000 [01:12<01:51, 27.94it/s, loss=9.2977] ","output_type":"stream"},{"name":"stdout","text":"Warning: NaN loss detected!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:  65%|██████▌   | 3267/5000 [02:05<01:03, 27.39it/s, loss=10.8853]","output_type":"stream"},{"name":"stdout","text":"Warning: NaN loss detected!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 5000/5000 [03:11<00:00, 26.15it/s, loss=10.6056]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 191\nEpoch 9 Complete - Average Loss: 9.9998\nModel saved at epoch 8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 5000/5000 [03:10<00:00, 26.20it/s, loss=8.9049] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 10 Complete - Average Loss: 9.9812\nModel saved at epoch 9\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 5000/5000 [03:11<00:00, 26.12it/s, loss=7.4476] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 191\nEpoch 11 Complete - Average Loss: 9.9665\nModel saved at epoch 10\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12:  43%|████▎     | 2126/5000 [01:21<01:45, 27.34it/s, loss=10.2382]","output_type":"stream"},{"name":"stdout","text":"Warning: NaN loss detected!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 5000/5000 [03:11<00:00, 26.15it/s, loss=9.6645] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 191\nEpoch 12 Complete - Average Loss: 9.9560\nModel saved at epoch 11\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 5000/5000 [03:10<00:00, 26.20it/s, loss=9.9357] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 13 Complete - Average Loss: 9.9360\nModel saved at epoch 12\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14:  80%|███████▉  | 3978/5000 [02:31<00:37, 27.10it/s, loss=8.0623] ","output_type":"stream"},{"name":"stdout","text":"Warning: NaN loss detected!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 5000/5000 [03:10<00:00, 26.23it/s, loss=8.9258] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 14 Complete - Average Loss: 9.9240\nModel saved at epoch 13\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 5000/5000 [03:10<00:00, 26.20it/s, loss=10.4354]\n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 15 Complete - Average Loss: 9.9211\nModel saved at epoch 14\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16:  62%|██████▏   | 3113/5000 [01:58<01:07, 27.87it/s, loss=9.2893] ","output_type":"stream"},{"name":"stdout","text":"Warning: NaN loss detected!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|██████████| 5000/5000 [03:10<00:00, 26.19it/s, loss=8.6344] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 16 Complete - Average Loss: 9.9080\nModel saved at epoch 15\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 5000/5000 [03:11<00:00, 26.15it/s, loss=8.7018] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 191\nEpoch 17 Complete - Average Loss: 9.9116\nModel saved at epoch 16\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18:   2%|▏         | 83/5000 [00:03<03:05, 26.51it/s, loss=11.3664]","output_type":"stream"},{"name":"stdout","text":"Warning: NaN loss detected!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|██████████| 5000/5000 [03:10<00:00, 26.20it/s, loss=9.8348] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 18 Complete - Average Loss: 9.9041\nModel saved at epoch 17\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19: 100%|██████████| 5000/5000 [03:10<00:00, 26.18it/s, loss=9.6436] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 19 Complete - Average Loss: 9.8999\nModel saved at epoch 18\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20: 100%|██████████| 5000/5000 [03:10<00:00, 26.19it/s, loss=9.1760] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 20 Complete - Average Loss: 9.8984\nModel saved at epoch 19\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|██████████| 5000/5000 [03:10<00:00, 26.23it/s, loss=9.5356] \n","output_type":"stream"},{"name":"stdout","text":"Time Taken for the epoch 190\nEpoch 21 Complete - Average Loss: 9.9020\nModel saved at epoch 20\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22:  72%|███████▏  | 3598/5000 [02:17<00:53, 26.24it/s, loss=7.7761] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/108382643.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Stability: Clip gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36m_no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_no_grad_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_no_grad_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_no_grad_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_device_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         ):\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mnorms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":74},{"id":"04c5afb7-36d2-4c29-bcfa-d67e2020d52b","cell_type":"code","source":"loss=evaluate(test_dataloader,model,loss_ns,loss_mlm)\nloss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:42:02.311677Z","iopub.status.idle":"2026-01-28T19:42:02.311904Z","shell.execute_reply.started":"2026-01-28T19:42:02.311797Z","shell.execute_reply":"2026-01-28T19:42:02.311810Z"}},"outputs":[],"execution_count":null},{"id":"c37c862b-3e22-4b1e-a84d-01ba036bf76a","cell_type":"code","source":"test_dataset_actual= '/kaggle/input/bert-dataset/bert_dataset/bert_test_data.csv'\ntest_dataloader = DataLoader(test_dataset_actual, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\nloss=evaluate(test_dataloader,model,loss_ns,loss_mlm)\nloss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:42:02.313050Z","iopub.status.idle":"2026-01-28T19:42:02.313356Z","shell.execute_reply.started":"2026-01-28T19:42:02.313242Z","shell.execute_reply":"2026-01-28T19:42:02.313257Z"}},"outputs":[],"execution_count":null},{"id":"d5d78b63-fc92-400e-90be-bc43fdf9ee21","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}